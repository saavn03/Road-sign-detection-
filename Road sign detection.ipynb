{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROAD SIGN DETECTION USING KNN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages,libraries and modules imported and used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths of images saved\n",
    "folder1=r\"Enter your dataset folder path here\\dataset\\STOP SIGN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for stop sign images \n",
    "\n",
    "for filename in os.listdir(folder1):\n",
    "    path=os.path.join(folder1,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)#resize image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)stop_sign.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128119, 128)\n"
     ]
    }
   ],
   "source": [
    "#Feature vector of stop sign Dataset\n",
    "data1= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)stop_sign.csv\")\n",
    "data1=data1.astype(np.uint8)\n",
    "\n",
    "#shape\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on stop sign class\n",
    "#stop sign\n",
    "kmeans1 = KMeans(n_clusters=5)\n",
    "kmeans1.fit(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of stop sign\n",
      "(array([20992, 31044, 15286, 21897, 38900], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#histograms of stop sign\n",
    "\n",
    "hist1=np.histogram(kmeans1.labels_,bins=[0,1,2,3,4,5])\n",
    "print('histogram of stop sign')\n",
    "print(hist1,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire stop sign dataset with the pretrained kmeans model\n",
    "\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=1\n",
    "data=[]\n",
    "\n",
    "for filename in os.listdir(folder1):\n",
    "    path=os.path.join(folder1,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans1.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)_stopsignFinal.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP SIGN\n",
      "     0  156   192   96  204  204.1  1\n",
      "0    1  166   207   96   88    280  1\n",
      "1    2  135   287   82  333    347  1\n",
      "2    3   42    75   45  206     90  1\n",
      "3    4  372  1325  282  517   1604  1\n",
      "4    5   39    65   17   55     82  1\n",
      "..  ..  ...   ...  ...  ...    ... ..\n",
      "78  79  397   613  206  333    796  1\n",
      "79  80  102   114  112  196    196  1\n",
      "80  81  396   395  344  251    620  1\n",
      "81  82  257   239  209  364    448  1\n",
      "82  83  364   515  190  471    572  1\n",
      "\n",
      "[83 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Displaying the kmeans predicted data\n",
    "print(\"STOP SIGN\")\n",
    "dat1= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)_stopsignFinal.csv\")\n",
    "print(dat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder2=r\"Enter your dataset folder path here\\dataset\\LEFT TURN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for left turn images \n",
    "\n",
    "for filename in os.listdir(folder2):\n",
    "    path=os.path.join(folder2,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)#resize image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)left_turn.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144076, 128)\n"
     ]
    }
   ],
   "source": [
    "#Feature vector of left turn Dataset\n",
    "data2= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)left_turn.csv\")\n",
    "data2=data2.astype(np.uint8)\n",
    "#shape\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on left turn class\n",
    "#left turn\n",
    "kmeans2 = KMeans(n_clusters=5)\n",
    "kmeans2.fit(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of left turn\n",
      "(array([43612, 24053, 46999, 13213, 16199], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist2=np.histogram(kmeans2.labels_,bins=[0,1,2,3,4,5])\n",
    "print('histogram of left turn')\n",
    "print(hist2,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire left turn dataset with the pretrained kmeans model\n",
    "#initialising i=0; as its the first class\n",
    "i=2\n",
    "data=[]\n",
    "\n",
    "for filename in os.listdir(folder2):\n",
    "    path=os.path.join(folder2,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "\n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans2.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)_leftturnFinal.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT TURN\n",
      "       0   65  153   99   41   27  2\n",
      "0      1   27   14   20   38   61  2\n",
      "1      2  160  214  168   78   88  2\n",
      "2      3  396  189  604  206  129  2\n",
      "3      4   27   14   12   35    2  2\n",
      "4      5  490  210  421  205  159  2\n",
      "..   ...  ...  ...  ...  ...  ... ..\n",
      "98    99  323  278  485   72  159  2\n",
      "99   100   89  171  139   98   52  2\n",
      "100  101   20   99   57    0   15  2\n",
      "101  102  707  124  731  101   54  2\n",
      "102  103  181  350  181  321  648  2\n",
      "\n",
      "[103 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Displaying the kmeans predicted data\n",
    "print(\"LEFT TURN\")\n",
    "dat2= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)_leftturnFinal.csv\")\n",
    "print(dat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder3=r\"Enter your dataset folder path here\\dataset\\MEN AT WORK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for men at work images \n",
    "\n",
    "for filename in os.listdir(folder3):\n",
    "    path=os.path.join(folder3,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)#resize image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)menatwork.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171237, 128)\n"
     ]
    }
   ],
   "source": [
    "#Feature vector of men at work Dataset\n",
    "data3= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)menatwork.csv\")\n",
    "data3=data3.astype(np.uint8)\n",
    "\n",
    "#shape\n",
    "print(data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on men at work class\n",
    "#men at work\n",
    "kmeans3 = KMeans(n_clusters=5)\n",
    "kmeans3.fit(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of men at work\n",
      "(array([18596, 25438, 16661, 55126, 55416], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist3=np.histogram(kmeans3.labels_,bins=[0,1,2,3,4,5])\n",
    "print('histogram of men at work')\n",
    "print(hist3,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire men at work dataset with the pretrained kmeans model\n",
    "\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=3\n",
    "data=[]\n",
    "\n",
    "for filename in os.listdir(folder3):\n",
    "    path=os.path.join(folder3,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "\n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans3.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)_menatworkFinal.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEN AT WORK\n",
      "     0   30   76   23   122  76.1  3\n",
      "0    1  236  318  182   714   729  3\n",
      "1    2  109  390   87   158   135  3\n",
      "2    3   28  147   27   110   124  3\n",
      "3    4  185  122   82   481   514  3\n",
      "4    5  176  112  101   421   369  3\n",
      "..  ..  ...  ...  ...   ...   ... ..\n",
      "94  95  154  294  246   892  1081  3\n",
      "95  96  203  227  124   745   731  3\n",
      "96  97  295  314  267  1483  1519  3\n",
      "97  98  396  433  291   589   651  3\n",
      "98  99  223  174  194   548   600  3\n",
      "\n",
      "[99 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Displaying the kmeans predicted data\n",
    "print(\"MEN AT WORK\")\n",
    "dat3= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)_menatworkFinal.csv\")\n",
    "print(dat3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder4=r\"Enter your dataset folder path here\\dataset\\GO RIGHT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction for go right images \n",
    "\n",
    "for filename in os.listdir(folder4):\n",
    "    path=os.path.join(folder4,filename)\n",
    "    a=cv2.imread(path)\n",
    "    \n",
    "    #resize image\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)#resize image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    \n",
    "    #append to the csv file\n",
    "    csv_data=out.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)goright.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97605, 128)\n"
     ]
    }
   ],
   "source": [
    "#Feature vector of go right Dataset\n",
    "data4= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)goright.csv\")\n",
    "data4=data4.astype(np.uint8)\n",
    "\n",
    "#shape\n",
    "print(data4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing kmeans on each class\n",
    "#go right\n",
    "kmeans4 = KMeans(n_clusters=5)\n",
    "kmeans4.fit(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "histogram of go right\n",
      "(array([29906, 10185, 16620, 31279,  9615], dtype=int64), array([0, 1, 2, 3, 4, 5])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist4=np.histogram(kmeans4.labels_,bins=[0,1,2,3,4,5])\n",
    "print('histogram of go right')\n",
    "print(hist4,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing kmeans prediction of the entire go right dataset with the pretrained kmeans model\n",
    "\n",
    "\n",
    "#initialising i=0; as its the first class\n",
    "i=4\n",
    "data=[]\n",
    "\n",
    "for filename in os.listdir(folder4):\n",
    "    path=os.path.join(folder4,filename)\n",
    "    a=cv2.imread(path)\n",
    "    resize=(512,512)\n",
    "    img=cv2.resize(a,resize)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #initialise sift descriptor\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    #convert the descriptor array into a dataframe format\n",
    "    out=pd.DataFrame(descriptors)\n",
    "    array_double = np.array(out, dtype=np.double)\n",
    "    a=kmeans4.predict(array_double)\n",
    "    hist=np.histogram(a,bins=[0,1,2,3,4,5])\n",
    "    #append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "    data.append(hist[0])\n",
    "    \n",
    "#convert Array to Dataframe and append to the list\n",
    "Output = pd.DataFrame(data)\n",
    "#add row class \n",
    "Output[\"Class\"] = i \n",
    "csv_data=Output.to_csv('Enter your dataset folder path here\\dataset\\SIFT(LAB13)_gorightFinal.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO RIGHT\n",
      "     0   192   27  130   128   83  4\n",
      "0    1   163   81   62   143  147  4\n",
      "1    2   349  298  153   409  211  4\n",
      "2    3  1710  481  396  1502  580  4\n",
      "3    4   631  167  406   550  204  4\n",
      "4    5   747  153  504   949  149  4\n",
      "..  ..   ...  ...  ...   ...  ... ..\n",
      "66  67   800  315  300   898  161  4\n",
      "67  68    29    5   47    22   19  4\n",
      "68  69   479  197  172   540  140  4\n",
      "69  70   707  260  416   677  273  4\n",
      "70  71   216  114  370   266  118  4\n",
      "\n",
      "[71 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Displaying the kmeans predicted data\n",
    "print(\"GO RIGHT\")\n",
    "dat4= pd.read_csv(r\"Enter your dataset folder path here\\dataset\\SIFT(LAB13)_gorightFinal.csv\")\n",
    "print(dat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending All classes into 1 csv file\n",
    "\n",
    "A=dat1.append(dat2)\n",
    "A=A.append(dat3)\n",
    "A=A.append(dat4)\n",
    "\n",
    "csv_data=A.to_csv('SIFT(LAB14)_Final.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     No_of_feature    1     2    3    4     5  Class\n",
      "0                2  135   287   82  333   347      1\n",
      "1                3   42    75   45  206    90      1\n",
      "2                4  372  1325  282  517  1604      1\n",
      "3                5   39    65   17   55    82      1\n",
      "4                6  150   143  139  220   144      1\n",
      "..             ...  ...   ...  ...  ...   ...    ...\n",
      "350             67  800   315  300  898   161      4\n",
      "351             68   29     5   47   22    19      4\n",
      "352             69  479   197  172  540   140      4\n",
      "353             70  707   260  416  677   273      4\n",
      "354             71  216   114  370  266   118      4\n",
      "\n",
      "[355 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv(r\"D:\\PYTHON\\COMPUTER VISION\\COURSE PROJECT\\dataset\\SIFT(LAB14)_Final.csv\")\n",
    "data.columns=['No_of_feature','1','2','3','4','5','Class']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values\n",
      "       1     2    3    4     5\n",
      "0    135   287   82  333   347\n",
      "1     42    75   45  206    90\n",
      "2    372  1325  282  517  1604\n",
      "3     39    65   17   55    82\n",
      "4    150   143  139  220   144\n",
      "..   ...   ...  ...  ...   ...\n",
      "350  800   315  300  898   161\n",
      "351   29     5   47   22    19\n",
      "352  479   197  172  540   140\n",
      "353  707   260  416  677   273\n",
      "354  216   114  370  266   118\n",
      "\n",
      "[355 rows x 5 columns]\n",
      "Y values\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "350    4\n",
      "351    4\n",
      "352    4\n",
      "353    4\n",
      "354    4\n",
      "Name: Class, Length: 355, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#assigning x the columns from 1 to 5 for training\n",
    "x = data.iloc[:, 1:6]\n",
    "print(\"X values\")\n",
    "print(x)\n",
    "\n",
    "#assigning y with the column \"Class\" as target variable\n",
    "y = data['Class']\n",
    "print(\"Y values\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.590267</td>\n",
       "      <td>0.166369</td>\n",
       "      <td>-0.695175</td>\n",
       "      <td>-0.022870</td>\n",
       "      <td>0.030348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.892064</td>\n",
       "      <td>-0.893110</td>\n",
       "      <td>-0.833501</td>\n",
       "      <td>-0.402224</td>\n",
       "      <td>-0.713153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178830</td>\n",
       "      <td>5.353818</td>\n",
       "      <td>0.052529</td>\n",
       "      <td>0.526746</td>\n",
       "      <td>3.666846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.901800</td>\n",
       "      <td>-0.943085</td>\n",
       "      <td>-0.938179</td>\n",
       "      <td>-0.853268</td>\n",
       "      <td>-0.736296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.541590</td>\n",
       "      <td>-0.553277</td>\n",
       "      <td>-0.482080</td>\n",
       "      <td>-0.360406</td>\n",
       "      <td>-0.556931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1.567747</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.119822</td>\n",
       "      <td>1.664810</td>\n",
       "      <td>-0.507750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.934251</td>\n",
       "      <td>-1.242938</td>\n",
       "      <td>-0.826024</td>\n",
       "      <td>-0.951841</td>\n",
       "      <td>-0.918555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.526059</td>\n",
       "      <td>-0.283410</td>\n",
       "      <td>-0.358708</td>\n",
       "      <td>0.595448</td>\n",
       "      <td>-0.568503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>1.265949</td>\n",
       "      <td>0.031435</td>\n",
       "      <td>0.553491</td>\n",
       "      <td>1.004674</td>\n",
       "      <td>-0.183734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.327411</td>\n",
       "      <td>-0.698206</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>-0.223002</td>\n",
       "      <td>-0.632149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "0   -0.590267  0.166369 -0.695175 -0.022870  0.030348\n",
       "1   -0.892064 -0.893110 -0.833501 -0.402224 -0.713153\n",
       "2    0.178830  5.353818  0.052529  0.526746  3.666846\n",
       "3   -0.901800 -0.943085 -0.938179 -0.853268 -0.736296\n",
       "4   -0.541590 -0.553277 -0.482080 -0.360406 -0.556931\n",
       "..        ...       ...       ...       ...       ...\n",
       "350  1.567747  0.306300  0.119822  1.664810 -0.507750\n",
       "351 -0.934251 -1.242938 -0.826024 -0.951841 -0.918555\n",
       "352  0.526059 -0.283410 -0.358708  0.595448 -0.568503\n",
       "353  1.265949  0.031435  0.553491  1.004674 -0.183734\n",
       "354 -0.327411 -0.698206  0.381519 -0.223002 -0.632149\n",
       "\n",
       "[355 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standard scaling\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "x=DataFrame(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset split into train and test with 80% Training and 20% Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.74      0.70      0.72        20\n",
      "           2       0.91      1.00      0.95        20\n",
      "           3       0.75      0.78      0.77        23\n",
      "           4       1.00      0.75      0.86         8\n",
      "\n",
      "    accuracy                           0.82        71\n",
      "   macro avg       0.85      0.81      0.82        71\n",
      "weighted avg       0.82      0.82      0.82        71\n",
      "\n",
      "KNN:  0.8169014084507042\n"
     ]
    }
   ],
   "source": [
    "# import sklearn.metrics as metrics\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from sklearn import svm\n",
    "\n",
    "# #Create a svm Classifier\n",
    "# model1 = svm.SVC(kernel='linear')\n",
    "\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# model1.fit(x_train, y_train)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred1 = model1.predict(x_test)\n",
    "# #Results\n",
    "# print(\"SVM Results\")\n",
    "# print(classification_report(y_test, y_pred1))\n",
    "# print(\"SVM: \",accuracy_score(y_test, y_pred1))\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Create a KNN Classifier\n",
    "model = KNeighborsClassifier(n_neighbors = 8)\n",
    "\n",
    "#Train the model using the training sets\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "pred=model.predict(x_test) \n",
    "#Results\n",
    "print(\"KNN Results\")\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"KNN: \",accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3    4\n",
      "0  109  159  153  191  240\n"
     ]
    }
   ],
   "source": [
    "#Recognition &Validation\n",
    "#Assigning path with any any class image\n",
    "path=r\"D:\\PYTHON\\COMPUTER VISION\\COURSE PROJECT\\dataset\\STOP SIGN\\1.jpg\"\n",
    "data=[]\n",
    "\n",
    "#Repeated the process of image pre-processing and feature extraction\n",
    "a=cv2.imread(path)\n",
    "resize=(512,512)\n",
    "\n",
    "#resize image\n",
    "img=cv2.resize(a,resize)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#initialise sift descriptor\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "\n",
    "#convert the descriptor array into a dataframe format\n",
    "out=pd.DataFrame(descriptors)\n",
    "\n",
    "#initialise Kmeans and create 5 clusters\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "#train the model for the features i.e. for all elements in the Dataframe\n",
    "kmeans.fit(out.values)\n",
    "\n",
    "#get the values of the histogram for one image only for 5 clusters i.e. in 5 bins\n",
    "#kmeans.labels_ give us the label vlaue of the feature that its clustered into\n",
    "#hist will give the hostogram for all those vlaues\n",
    "hist=np.histogram(kmeans.labels_,bins=[0,1,2,3,4,5])\n",
    "\n",
    "#append the dataframe into the array in append mode, the array will only have 5 values which will store the values in a row\n",
    "data.append(hist[0])\n",
    "\n",
    "Output = pd.DataFrame(data)\n",
    "print(Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# # #assigning the columns 1 to 128 of new image as training variables\n",
    "x = Output.iloc[:, 0:5]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x=sc.transform(x)\n",
    "\n",
    "#prediction\n",
    "y_pred1 = model.predict(x)\n",
    "\n",
    "#prints the prediction of the class\n",
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop sign\n"
     ]
    }
   ],
   "source": [
    "if ((y_pred1)==1):\n",
    "    print(\"stop sign\")\n",
    "elif ((y_pred1)==2):\n",
    "    print(\"left turn\")\n",
    "elif ((y_pred1)==3):\n",
    "    print(\"men at work\")\n",
    "else:\n",
    "    print(\"go right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
